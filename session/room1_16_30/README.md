# Unleashing the Power of Vector Search and Semantic Caching in .NET
**Room:** Live in Rome 1

**Start Time:** 2024-03-22 16:30

This presentation delves into the innovative capabilities of vector search and semantic caching within the .NET framework, with a focus on the Redis OM library.

Redis OM .NET has evolved to embrace the transformative world of vector database technology, now supporting Redis vector search and seamless integration with OpenAI, Azure OpenAI, Hugging Face, and ML.NET. This talk highlights the latest advancements in Redis OM .NET, focusing on how it simplifies the complex process of vector indexing, data modeling, and querying for AI-powered applications.

Vector databases are redefining data handling, enabling semantic searches across text, images, and audio encoded as vectors. Redis OM .NET simplifies this innovative approach, making it accessible even for those new to vector data. We will explore the new capabilities of Redis OM .NET, including intuitive vector search interfaces and semantic caching, which reduce the overhead of large language model (LLM) calls.

The session will delve into the practical aspects of using Redis OM .NET for vector data management, covering topics like modeling and index creation, querying techniques including nearest neighbors and vector range searches, hybrid queries, and custom vector generation. These enhancements to Redis OM .NET not only make vector search more intuitive but also condense what was once a complex implementation into a few straightforward lines of code.
![Banner](room1_16_30.jpeg 'SessionBanner')
![QR](qr.png 'Qr')
![Voting Banner](votingBanner.png 'Voting Banner')

